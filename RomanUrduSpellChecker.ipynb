{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "NLP-Assignment 4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1: Reading Data file."
      ],
      "metadata": {
        "id": "LGYbFOkVc7kU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import csv\r\n",
        "import spacy\r\n",
        "import string\r\n",
        "import numpy as np"
      ],
      "outputs": [],
      "metadata": {
        "id": "7V0WqiyUh-u2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-Yl1WEZD4XD",
        "outputId": "8010c26a-77eb-42b8-8bbb-b2b5c68e3810"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "with open('/content/drive/MyDrive/data.txt','r') as f:\r\n",
        "   words = f.read().split()\r\n",
        "\r\n",
        "print(len(words)) #10 seconds."
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt6M3MXNWWGP",
        "outputId": "c3b27c13-2028-4558-f673-d581195279e7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: Reading Misspellings file."
      ],
      "metadata": {
        "id": "W8p8IXoheGxA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "misspellings = dict()\r\n",
        "with open('/content/drive/MyDrive/misspellings.txt') as csv_file:\r\n",
        "  csv_reader = csv.reader(csv_file,delimiter=',')\r\n",
        "  index = 0\r\n",
        "  for row in csv_reader:\r\n",
        "    if index == 0:\r\n",
        "      index += 1\r\n",
        "      continue\r\n",
        "    else:\r\n",
        "      temp = row[1].split('\\t')\r\n",
        "      for i in range(len(temp)):\r\n",
        "        temp[i] = temp[i].strip()\r\n",
        "      misspellings[row[0]] = temp\r\n",
        "      index += 1\r\n",
        "misspellings # 3 seconds."
      ],
      "outputs": [],
      "metadata": {
        "id": "tYEo0OA1eMj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6791a1c-9d59-40ad-84d6-cf1adb2c0a7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3: Generating Unigram Model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zLBb1QW3dEjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finds the count of each word, then divides by the total number of words in the data corpus."
      ],
      "metadata": {
        "id": "yulpM6d38JsF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "wordOccurrences = dict()\r\n",
        "for word in words:\r\n",
        "  if word not in wordOccurrences:\r\n",
        "    wordOccurrences[word] = 1\r\n",
        "  else:\r\n",
        "    wordOccurrences[word] += 1\r\n",
        "\r\n",
        "unigrams = dict()\r\n",
        "for key, value in wordOccurrences.items():\r\n",
        "  unigrams[key] = (value / len(words))\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "Wfjhlf57Ul9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4: Creation of insert, delete, substitution and transposition tables."
      ],
      "metadata": {
        "id": "50wuBNqEdqPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***4.1 Initializing tables.***"
      ],
      "metadata": {
        "id": "G5LZHUMFt1cS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializes the tables in form of a dictionary. Alphabets are tuples, which represent keys and values are the occurrences of those alphabets in that order."
      ],
      "metadata": {
        "id": "Trk2N6eF8fGw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "alphabet = string.ascii_lowercase\r\n",
        "alphabets = list(alphabet)\r\n",
        "alphabets = alphabets + ['#']\r\n",
        "insert_table = dict()\r\n",
        "delete_table = dict()\r\n",
        "substitution_table = dict()\r\n",
        "transposition_table = dict()\r\n",
        "for u in alphabets:\r\n",
        "  for e in alphabets:\r\n",
        "    if e == '#':\r\n",
        "      continue\r\n",
        "    insert_table[u,e] = 0\r\n",
        "    delete_table[u,e] = 0\r\n",
        "    substitution_table[u,e] = 0\r\n",
        "    transposition_table[u,e] = 0\r\n",
        "for key,value in insert_table.items():\r\n",
        "  print(key,value)"
      ],
      "outputs": [],
      "metadata": {
        "id": "hcd9fnO2dsOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f595cf-2dbf-4115-c287-1bf5635e2924"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***4.2 Populating tables.***"
      ],
      "metadata": {
        "id": "_8oGZbVluCeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterates over the words in misspellings. For each wrongly spelt word, we find the type of operant used on that particular word i.e. insert, delete, substitution and transpose. After finding the operant used, we incrememt the two alphabets in the respective tables for insert, delete, substitution and transpose."
      ],
      "metadata": {
        "id": "fM1gvAYQ81qv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def populateTables():\r\n",
        "  for correct_word, wrong_words in misspellings.items():\r\n",
        "    for wrong_word in wrong_words:\r\n",
        "      if len(correct_word) == len(wrong_word): # Either substitution or transpose.\r\n",
        "        for i in range(len(correct_word)):\r\n",
        "          if correct_word[i] != wrong_word[i]:\r\n",
        "            if i != len(wrong_word)-1 and (correct_word[i] == wrong_word[i+1] and correct_word[i+1] == wrong_word[i]): #Transposition.\r\n",
        "              u = correct_word[i]\r\n",
        "              e = correct_word[i+1]\r\n",
        "              transposition_table[u,e] += 1\r\n",
        "              break\r\n",
        "            else: #Substitution\r\n",
        "              u = correct_word[i]\r\n",
        "              e = wrong_word[i]\r\n",
        "              substitution_table[u,e] += 1\r\n",
        "              break\r\n",
        "      elif len(wrong_word) > len(correct_word): # Insertion.\r\n",
        "        if (correct_word[0] != wrong_word[0]): #Starting letters don't match.\r\n",
        "          u = '#'\r\n",
        "          e = wrong_word[0]\r\n",
        "          insert_table[u,e] += 1\r\n",
        "        elif (correct_word[-1] != wrong_word[-1]): #Ending letters don't match.\r\n",
        "          u = correct_word[-1]\r\n",
        "          e = wrong_word[-1]\r\n",
        "          insert_table[u,e] += 1\r\n",
        "        else:\r\n",
        "          for i in range(len(correct_word)):\r\n",
        "            if correct_word[i] != wrong_word[i]: #Middle letters don't match.\r\n",
        "              u = correct_word[i-1]\r\n",
        "              e = wrong_word[i]\r\n",
        "              insert_table[u,e] += 1\r\n",
        "              break\r\n",
        "          \r\n",
        "\r\n",
        "      elif len(wrong_word) < len(correct_word): #Deletion.\r\n",
        "        if (correct_word[0] != wrong_word[0]): #Starting letters don't match.\r\n",
        "          u = '#'\r\n",
        "          e = correct_word[0]\r\n",
        "          delete_table[u,e] += 1\r\n",
        "        elif (correct_word[-1] != wrong_word[-1]): #Ending letters don't match.\r\n",
        "          u = wrong_word[-1]\r\n",
        "          e = correct_word[-1]\r\n",
        "          delete_table[u,e] += 1\r\n",
        "        else:\r\n",
        "          for i in range(len(wrong_word)):\r\n",
        "            if correct_word[i] != wrong_word[i]: #Middle letters don't match.\r\n",
        "              u = correct_word[i-1]\r\n",
        "              e = correct_word[i]\r\n",
        "              delete_table[u,e] += 1\r\n",
        "              break\r\n",
        "\r\n",
        "populateTables()\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "UE4TmWdTuz4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5: Creating Error Models."
      ],
      "metadata": {
        "id": "IFz60fcRMU7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***5.1 Finding character level unigram.***"
      ],
      "metadata": {
        "id": "azD5IV6uMmte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each letter in data.txt, we find the occurrences. "
      ],
      "metadata": {
        "id": "qvE0nLqO95n7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "letterUnigrams = dict()\r\n",
        "for word in words:\r\n",
        "  for letter in word:\r\n",
        "    if letter not in letterUnigrams:\r\n",
        "      letterUnigrams[letter] = 1\r\n",
        "    else:\r\n",
        "      letterUnigrams[letter] += 1\r\n",
        "#55 seconds."
      ],
      "outputs": [],
      "metadata": {
        "id": "zUI0uwMJ5eme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***5.2 Finding character level bigrams.***"
      ],
      "metadata": {
        "id": "tj0itOq1M1h_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each bigram letter in data.txt, we find the occurrences and also add ('#',letter) for our channel model."
      ],
      "metadata": {
        "id": "l_ELdf3c9_pC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "letterBigrams = dict()\r\n",
        "for word in words:\r\n",
        "  hashBigram = tuple(('#',word[0]))\r\n",
        "  if hashBigram not in letterBigrams:\r\n",
        "    letterBigrams[hashBigram] = 1\r\n",
        "  else:\r\n",
        "    letterBigrams[hashBigram] += 1\r\n",
        "  for i in range(len(word)-1):\r\n",
        "    letter1 = word[i]\r\n",
        "    letter2 = word[i+1]\r\n",
        "    if tuple((letter1,letter2)) not in letterBigrams:\r\n",
        "      letterBigrams[letter1,letter2] = 1\r\n",
        "    else:\r\n",
        "      letterBigrams[letter1,letter2] += 1\r\n",
        "      \r\n",
        "letterBigrams # 3 minute 30 seconds."
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U07GixRiMQyi",
        "outputId": "f927777d-67cf-49c2-cc00-38cc1deb7506"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***5.3 Calculating Edit Distance***"
      ],
      "metadata": {
        "id": "Xv7G8zD-j7g-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finds the levenshtein edit distance between two words."
      ],
      "metadata": {
        "id": "6LJ31gVN-Uc0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def calculateEditDistance(word1,word2,size1,size2):\r\n",
        "    size1=size1+1\r\n",
        "    size2=size2+1\r\n",
        "\r\n",
        "    editDistanceMatrix = {}\r\n",
        "    for i in range(size1): \r\n",
        "      editDistanceMatrix[i,0]=i\r\n",
        "    for j in range(size2): \r\n",
        "      editDistanceMatrix[0,j]=j\r\n",
        "    for i in range(1, size1):\r\n",
        "        for j in range(1, size2):\r\n",
        "            if word1[i-1] == word2[j-1]:\r\n",
        "              cost = 0\r\n",
        "            else:\r\n",
        "              cost = 1\r\n",
        "            editDistanceMatrix[i,j] = min(editDistanceMatrix[i, j-1]+1, \r\n",
        "                                          editDistanceMatrix[i-1, j]+1, \r\n",
        "                                          editDistanceMatrix[i-1, j-1]+cost)\r\n",
        "    return editDistanceMatrix[i,j]\r\n",
        "print(calculateEditDistance(\"ussay\",\"usay\",5,4))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwS8lP9NkAhW",
        "outputId": "e0c9dd5e-e0b4-488b-c865-0f462e42a9b0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***5.4 Generating Candidate Words***"
      ],
      "metadata": {
        "id": "CHkB_sTzjYiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From all the unique words in the vocabulary, finds all the candidate words on the basis of edit distance. If edit distance is 1 then it's either one of insertion, deletion or substitution. If it's 2, we check if it's the result of transpose. If it is transpose then we append else we ignore."
      ],
      "metadata": {
        "id": "Xp6Wk5CV-dio"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def getCandidateWords(input):\r\n",
        "  candidateWordsList = []\r\n",
        "  for word in wordOccurrences.keys():\r\n",
        "    if len(word) == len(input) or len(word)-1 == len(input) or len(word)+1 == len(input):\r\n",
        "      editDist = calculateEditDistance(input,word,len(input),len(word))\r\n",
        "      if editDist <= 2:\r\n",
        "        if editDist == 1:\r\n",
        "          candidateWordsList.append(word)\r\n",
        "        elif editDist == 2: #Transpose.\r\n",
        "          if len(word) == len(input): # Either substitution or transpose.\r\n",
        "            for i in range(len(input)):\r\n",
        "              if word[i] != input[i]:\r\n",
        "                if i != len(word)-1 and (input[i] == word[i+1] and input[i+1] == word[i]): #Transposition.\r\n",
        "                  candidateWordsList.append(word)\r\n",
        "                  break\r\n",
        "                else:\r\n",
        "                  break \r\n",
        "  return candidateWordsList\r\n",
        "\r\n",
        "getCandidateWords(\"kall\")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0QGL6Y68bNb",
        "outputId": "ea7bf3b2-43eb-49ce-bb2e-f77265674daf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***5.5 Finding operant used and edited letters.***"
      ],
      "metadata": {
        "id": "4sxivIT-X8--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finds the operant used along with the letters involved in that operant and returns these as a list."
      ],
      "metadata": {
        "id": "I4ZNSVZON962"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def findEditOperantLetters(inputWord,candidateWord):\r\n",
        "  correct_word = candidateWord\r\n",
        "  wrong_word = inputWord\r\n",
        "  if len(correct_word) == len(wrong_word): # Either substitution or transpose.\r\n",
        "    for i in range(len(correct_word)):\r\n",
        "      if correct_word[i] != wrong_word[i]:\r\n",
        "        if i != len(wrong_word)-1 and (correct_word[i] == wrong_word[i+1] and correct_word[i+1] == wrong_word[i]): #Transposition.\r\n",
        "          temp = []\r\n",
        "          u = correct_word[i]\r\n",
        "          e = correct_word[i+1]\r\n",
        "          temp.append(u)\r\n",
        "          temp.append(e)\r\n",
        "          temp.append(\"Transpose\")\r\n",
        "          return temp\r\n",
        "        else: #Substitution\r\n",
        "          temp = []\r\n",
        "          u = correct_word[i]\r\n",
        "          e = wrong_word[i]\r\n",
        "          temp.append(u)\r\n",
        "          temp.append(e)\r\n",
        "          temp.append(\"Substitute\")\r\n",
        "          return temp\r\n",
        "  elif len(wrong_word) > len(correct_word): # Insertion.\r\n",
        "    if (correct_word[0] != wrong_word[0]): #Starting letters don't match.\r\n",
        "      temp = []\r\n",
        "      u = '#'\r\n",
        "      e = wrong_word[0]\r\n",
        "      temp.append(u)\r\n",
        "      temp.append(e)\r\n",
        "      temp.append(\"Insert\")\r\n",
        "      return temp\r\n",
        "    elif (correct_word[-1] != wrong_word[-1]): #Ending letters don't match.\r\n",
        "      temp = []\r\n",
        "      u = correct_word[-1]\r\n",
        "      e = wrong_word[-1]\r\n",
        "      temp.append(u)\r\n",
        "      temp.append(e)\r\n",
        "      temp.append(\"Insert\")\r\n",
        "      return temp\r\n",
        "    elif (correct_word[-1] == wrong_word[-1]):\r\n",
        "      temp = []\r\n",
        "      u = correct_word[-1]\r\n",
        "      e = wrong_word[-1]\r\n",
        "      temp.append(u)\r\n",
        "      temp.append(e)\r\n",
        "      temp.append(\"Insert\")\r\n",
        "      return temp\r\n",
        "    else:\r\n",
        "      for i in range(len(correct_word)):\r\n",
        "        if correct_word[i] != wrong_word[i]: #Middle letters don't match.\r\n",
        "          temp = []\r\n",
        "          u = correct_word[i-1]\r\n",
        "          e = wrong_word[i]\r\n",
        "          temp.append(u)\r\n",
        "          temp.append(e)\r\n",
        "          temp.append(\"Insert\")\r\n",
        "          return temp\r\n",
        "\r\n",
        "  elif len(wrong_word) < len(correct_word): #Deletion.\r\n",
        "    if (correct_word[0] != wrong_word[0]): #Starting letters don't match.\r\n",
        "      temp = []\r\n",
        "      u = '#'\r\n",
        "      e = correct_word[0]\r\n",
        "      temp.append(u)\r\n",
        "      temp.append(e)\r\n",
        "      temp.append(\"Delete\")\r\n",
        "      return temp\r\n",
        "    elif (correct_word[-1] != wrong_word[-1]): #Ending letters don't match.\r\n",
        "      temp = []\r\n",
        "      u = wrong_word[-1]\r\n",
        "      e = correct_word[-1]\r\n",
        "      temp.append(u)\r\n",
        "      temp.append(e)\r\n",
        "      temp.append(\"Delete\")\r\n",
        "      return temp\r\n",
        "    else:\r\n",
        "      for i in range(len(wrong_word)):\r\n",
        "        if correct_word[i] != wrong_word[i]: #Middle letters don't match.\r\n",
        "          temp = []\r\n",
        "          u = correct_word[i-1]\r\n",
        "          e = correct_word[i]\r\n",
        "          temp.append(u)\r\n",
        "          temp.append(e)\r\n",
        "          temp.append(\"Delete\")\r\n",
        "          return temp\r\n",
        "#Entered as inputWord, candidateWord. \r\n",
        "findEditOperantLetters(\"kall\",\"kal\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "o8QRtrDbVpNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9543ddd-7147-4478-d213-416b0c7843db"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***5.6 Channel Models and most probable corrected word.*** "
      ],
      "metadata": {
        "id": "VcVNcSsUnmYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the input, first we get all the candidate words, then for each of these candidate words we find P(x|w) using the formulas. This is stored in a dictionary. Once we do that, we use this dictionary to find the most probable word for the user's input and display that. If no candidate words were found then it returns a relevant statement."
      ],
      "metadata": {
        "id": "bmkoXRruOpzc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def channelModelProbabilities(input):\r\n",
        "  probabilities = dict()\r\n",
        "  candidateWords = getCandidateWords(input)\r\n",
        "  if len(candidateWords) == 0:\r\n",
        "    return None\r\n",
        "  else:\r\n",
        "    for word in candidateWords:\r\n",
        "      output = findEditOperantLetters(input,word)\r\n",
        "      if output[2] == 'Insert':\r\n",
        "        if output[0] == '#':\r\n",
        "          probabilities[word] = insert_table[(output[0],output[1])] / len(words)\r\n",
        "        else:\r\n",
        "          probabilities[word] = insert_table[(output[0],output[1])] / letterUnigrams[output[0]]\r\n",
        "      elif output[2] == 'Delete':\r\n",
        "        probabilities[word] = delete_table[(output[0],output[1])] / letterBigrams[(output[0],output[1])]\r\n",
        "      elif output[2] == 'Transpose':\r\n",
        "        probabilities[word] = transposition_table[(output[0],output[1])] / letterBigrams[(output[0],output[1])]\r\n",
        "      elif output[2] == 'Substitute':\r\n",
        "        probabilities[word] = substitution_table[(output[0],output[1])] / letterUnigrams[output[0]]\r\n",
        "    return probabilities\r\n",
        "\r\n",
        "def mostProbableCorrectedWord(input):\r\n",
        "  probabilities = channelModelProbabilities(input)\r\n",
        "  if probabilities == None:\r\n",
        "    return None\r\n",
        "  else:\r\n",
        "    for key,value in probabilities.items():\r\n",
        "      probabilities[key] = value * (unigrams[key]) \r\n",
        "    probableCorrectedWord = max(probabilities,key=probabilities.get)\r\n",
        "    return probableCorrectedWord\r\n",
        "\r\n",
        "output = mostProbableCorrectedWord(\"pak\")\r\n",
        "if output == None:\r\n",
        "  print(\"No words found...\")\r\n",
        "else:\r\n",
        "  print(output)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvayR00ahzRO",
        "outputId": "9169e4b6-310b-41a9-8bc8-8b6b32baa344"
      }
    }
  ]
}